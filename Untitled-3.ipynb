{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch \n",
    "from torch_geometric.data import HeteroData\n",
    "import itertools\n",
    "from torch_geometric.nn import Linear,SAGEConv, Sequential, to_hetero,GATConv\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.data import DataLoader\n",
    "from tqdm import *\n",
    "import objgraph\n",
    "import gc\n",
    "\n",
    "#导入数据并预处理\n",
    "data=pd.read_excel('C:\\\\Users\\\\Q\\\\Desktop\\\\Cu-Ni-Si博威迁移特征学习\\\\去除缺省值的电导率和硬度分布.xlsx')\n",
    "data_physical_property_all=data.iloc[:57,1:17]\n",
    "data_process_number=data.iloc[0,17:-2]\n",
    "#data_element_label=[i for i in data.columns[0:16]]\n",
    "#data_process_label=[i for i in data.columns[16:-2]]\n",
    "\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#device='cpu'\n",
    "#data_y_list=[]\n",
    "\n",
    "import random\n",
    "def setup_seed(seed):\n",
    "     torch.manual_seed(seed)\n",
    "     torch.cuda.manual_seed_all(seed)\n",
    "     np.random.seed(seed)\n",
    "     random.seed(seed)\n",
    "     torch.backends.cudnn.deterministic = True\n",
    "# 设置随机数种子\n",
    "setup_seed(3407)\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "        def __init__(self,add_self_loops,hidden_layer1,hidden_layer2,hidden_layer3):\n",
    "            super().__init__()\n",
    "\n",
    "            self.conv1 = GATConv((-1, -1), hidden_layer1,negative_slope=0,add_self_loops=add_self_loops)\n",
    "            self.conv2 = GATConv((-1, -1), hidden_layer2,negative_slope=0,add_self_loops=add_self_loops)\n",
    "            self.conv3 = GATConv((-1, -1), hidden_layer3,negative_slope=0,add_self_loops=add_self_loops)\n",
    "\n",
    "        def forward(self, x, edge_index):\n",
    "            x = self.conv1(x, edge_index)\n",
    "            x = self.conv2(x, edge_index)\n",
    "            x = self.conv3(x, edge_index)\n",
    "            return x\n",
    "        \n",
    "    \n",
    "class G_aggr(torch.nn.Module):\n",
    "    def __init__(self,layer3):\n",
    "        super().__init__()\n",
    "        self.lin=Linear(layer3,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=torch.sum(x['elements'],dim=0)+torch.sum(x['process'],dim=0)\n",
    "        x=self.lin(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class G_process(torch.nn.Module):\n",
    "    def __init__(self,metadata,hidden_layer1,hidden_layer2,hidden_layer3):\n",
    "        super().__init__()\n",
    "        self.encode = GNN(False,hidden_layer1,hidden_layer2,hidden_layer3)\n",
    "        self.encode=to_hetero(self.encode, metadata, aggr='sum').to(device)\n",
    "        self.decode=G_aggr(hidden_layer3)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        x=self.encode(x_dict, edge_index_dict)\n",
    "        x=self.decode(x)\n",
    "        return x\n",
    "\n",
    "metadata=(['elements', 'process'],\n",
    "        [('elements', 'e', 'elements'),\n",
    "        ('elements', 'e_p', 'process'),\n",
    "        ('process', 'p', 'process'),\n",
    "        ('process', 'rev_e_p', 'elements')])\n",
    "\n",
    "\n",
    "data_physical_property_new=pd.DataFrame(np.array(data_physical_property_all.drop([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,\n",
    "                                                                                  29,30,31,32,33,34,35,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,53,54,55])))\n",
    "\n",
    "\n",
    "for kkk in range(5):\n",
    "    data_physical_property=data_physical_property_new.drop([kkk])\n",
    "    data_H=[]\n",
    "    LOSS_dict={}\n",
    "    \n",
    "\n",
    "    for i in range(57,len(data),1):\n",
    "        data_1=data.iloc[i,1:]\n",
    "        data_1x=np.array(data_1.iloc[:-2])\n",
    "        data_1y=np.array(data_1.iloc[-2:])\n",
    "        E_label=data_1x[:16]==0\n",
    "        data_1H=HeteroData()\n",
    "        E_data=[]\n",
    "\n",
    "        #给元素点赋特征值\n",
    "        for k in range(len(E_label)):\n",
    "            if E_label[k]==False:\n",
    "                E_array=np.concatenate((np.array(data_1x[k]).reshape(-1),np.array(data_physical_property.iloc[:,k])),axis=0)\n",
    "                E_data.append(E_array)\n",
    "                \n",
    "        data_1H['elements'].x=torch.tensor(E_data,dtype=torch.float)\n",
    "        data_1H['elements'].x=torch.tensor(E_data,dtype=torch.float).to(device)\n",
    "        data_y=torch.tensor([data_1y[0],data_1y[1]],dtype=torch.float).to(device)\n",
    "        data_1H['elements'].y=data_y  \n",
    "\n",
    "        #给元素之间连边 \n",
    "        E_no_conbine=[i for i in range (len(E_data))]\n",
    "        E_conbine=list(itertools.combinations(E_no_conbine,2))\n",
    "        emelents_band_edge=torch.tensor(E_conbine).reshape(-1,2).T\n",
    "        data_1H['elements','e','elements'].edge_index = emelents_band_edge.to(device)  \n",
    "\n",
    "        #给工艺点赋特征值\n",
    "\n",
    "        P_label=data_1x[16:-2]==0\n",
    "        P_data=[]\n",
    "        for j in range(len(P_label)):\n",
    "            if P_label[j]==False:\n",
    "                P_data.append([data_process_number.iloc[j],data_1x[j+16]])\n",
    "\n",
    "        for i in P_data:\n",
    "            data_1H['process'].x=torch.tensor(P_data,dtype=torch.float).reshape(-1,2).to(device)\n",
    "            \n",
    "        #给元素和第一步工艺连边\n",
    "        data_1H['elements','e_p','process'].edge_index = torch.tensor([[x for x in range(len(E_data))],[0]*len(E_data)]).to(device)\n",
    "\n",
    "        #给工艺之间连边\n",
    "        if len(P_data) >1:\n",
    "            P_conbine=[[i for i in range (len(P_data)-1)],[i for i in range (1,len(P_data),1)]]\n",
    "            process_band_edge=torch.tensor(P_conbine).to(device)\n",
    "            data_1H['process','p','process'].edge_index = process_band_edge\n",
    "            \n",
    "        else:\n",
    "            data_1H['process','p','process'].edge_index = torch.tensor([[0],[0]]).to(device)\n",
    "            \n",
    "\n",
    "        data_1H=T.ToUndirected()(data_1H)    \n",
    "        #给合金赋性能值\n",
    "        #data_y_list.append(torch.tensor([data_1y[0],data_1y[1]],dtype=torch.float).to(device))\n",
    "        data_H.append(data_1H)\n",
    "    \n",
    "    train_data, test_data = train_test_split(data_H, test_size=0.2)\n",
    "    \n",
    "    #model=G_process(metadata,128,128,32).to(device)\n",
    "\n",
    "    model=torch.load('C:\\\\Users\\\\Q\\\\Desktop\\\\Cu-Ni-Si博威迁移特征学习\\\\最后_LR_0.0001_0.pth')\n",
    "    optimizer=torch.optim.Adam(model.parameters(),lr=0.0001)\n",
    "    scheduler=torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
    "    \n",
    "    length_train_data=len(train_data)\n",
    "    loss_fn = torch.nn.MSELoss(reduction='mean')\n",
    "    tr_loss_list=[]\n",
    "    te_loss_list=[]\n",
    "    for epoch in range(50):\n",
    "        tr_total_loss=0 \n",
    "        te_total_loss=0\n",
    "        '''if epoch%5==0:\n",
    "            for params in optimizer.param_groups:\n",
    "                params['lr']=params['lr']*0.9'''\n",
    "        #模型训练\n",
    "        for i in tqdm(range(len(train_data))):\n",
    "            x_data=train_data[i]\n",
    "            real_out=train_data[i]['elements'].y\n",
    "            out=model(x_data.x_dict,x_data.edge_index_dict)\n",
    "            loss=loss_fn(out,real_out)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tr_total_loss+=loss.item()\n",
    "            optimizer.zero_grad()\n",
    "        tr_total_loss=tr_total_loss/length_train_data\n",
    "        scheduler.step(tr_total_loss) \n",
    "        tr_loss_list.append(tr_total_loss) \n",
    "        #模型测试\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for i in test_data:\n",
    "                x_t_data=i\n",
    "                real_t_out=i['elements'].y \n",
    "                t_out=model(x_t_data.x_dict,x_t_data.edge_index_dict)\n",
    "                te_loss=loss_fn(t_out,real_t_out)\n",
    "                te_total_loss=te_total_loss+te_loss.item()\n",
    "            te_total_loss=te_total_loss/len(test_data)\n",
    "            te_loss_list.append(te_total_loss)\n",
    "            \n",
    "        #print(epoch,'   trainloss:',tr_total_loss,'   testloss:',te_total_loss)\n",
    "    LOSS_dict={'train_loss':tr_loss_list,'test_loss':te_loss_list}\n",
    "    loss_df=pd.DataFrame(LOSS_dict)\n",
    "    loss_df.to_excel('C:\\\\Users\\\\Q\\\\Desktop\\\\Cu-Ni-Si博威迁移特征学习\\\\LR_0.0001_loss_%s.xlsx'%kkk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "G_process(\n",
       "  (encode): GraphModule(\n",
       "    (conv1): Module(\n",
       "      (elements__e__elements): GATConv((-1, -1), 128, heads=1)\n",
       "      (elements__e_p__process): GATConv((-1, -1), 128, heads=1)\n",
       "      (process__p__process): GATConv((-1, -1), 128, heads=1)\n",
       "      (process__rev_e_p__elements): GATConv((-1, -1), 128, heads=1)\n",
       "    )\n",
       "    (conv2): Module(\n",
       "      (elements__e__elements): GATConv((-1, -1), 128, heads=1)\n",
       "      (elements__e_p__process): GATConv((-1, -1), 128, heads=1)\n",
       "      (process__p__process): GATConv((-1, -1), 128, heads=1)\n",
       "      (process__rev_e_p__elements): GATConv((-1, -1), 128, heads=1)\n",
       "    )\n",
       "    (conv3): Module(\n",
       "      (elements__e__elements): GATConv((-1, -1), 32, heads=1)\n",
       "      (elements__e_p__process): GATConv((-1, -1), 32, heads=1)\n",
       "      (process__p__process): GATConv((-1, -1), 32, heads=1)\n",
       "      (process__rev_e_p__elements): GATConv((-1, -1), 32, heads=1)\n",
       "    )\n",
       "  )\n",
       "  (decode): G_aggr(\n",
       "    (lin): Linear(32, 2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1melements\u001b[0m={\n",
       "    x=[3, 3],\n",
       "    y=[2]\n",
       "  },\n",
       "  \u001b[1mprocess\u001b[0m={ x=[2, 2] },\n",
       "  \u001b[1m(elements, e, elements)\u001b[0m={ edge_index=[2, 6] },\n",
       "  \u001b[1m(elements, e_p, process)\u001b[0m={ edge_index=[2, 3] },\n",
       "  \u001b[1m(process, p, process)\u001b[0m={ edge_index=[2, 2] },\n",
       "  \u001b[1m(process, rev_e_p, elements)\u001b[0m={ edge_index=[2, 3] }\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_H[0][]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.save(model,'C:\\\\Users\\\\Q\\\\Desktop\\\\Cu-Ni-Si博威迁移特征学习\\\\2_LR_0.0001_0.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_physical_property_new"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
